{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f97943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all required libraries\n"
     ]
    }
   ],
   "source": [
    "#Importing neccesary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "print(\"Imported all required libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6d3ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SPX</th>\n",
       "      <th>GLD</th>\n",
       "      <th>USO</th>\n",
       "      <th>SLV</th>\n",
       "      <th>EUR/USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2008</td>\n",
       "      <td>1447.160034</td>\n",
       "      <td>84.860001</td>\n",
       "      <td>78.470001</td>\n",
       "      <td>15.180</td>\n",
       "      <td>1.471692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/3/2008</td>\n",
       "      <td>1447.160034</td>\n",
       "      <td>85.570000</td>\n",
       "      <td>78.370003</td>\n",
       "      <td>15.285</td>\n",
       "      <td>1.474491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/4/2008</td>\n",
       "      <td>1411.630005</td>\n",
       "      <td>85.129997</td>\n",
       "      <td>77.309998</td>\n",
       "      <td>15.167</td>\n",
       "      <td>1.475492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/7/2008</td>\n",
       "      <td>1416.180054</td>\n",
       "      <td>84.769997</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>15.053</td>\n",
       "      <td>1.468299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/8/2008</td>\n",
       "      <td>1390.189941</td>\n",
       "      <td>86.779999</td>\n",
       "      <td>76.059998</td>\n",
       "      <td>15.590</td>\n",
       "      <td>1.557099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date          SPX        GLD        USO     SLV   EUR/USD\n",
       "0  1/2/2008  1447.160034  84.860001  78.470001  15.180  1.471692\n",
       "1  1/3/2008  1447.160034  85.570000  78.370003  15.285  1.474491\n",
       "2  1/4/2008  1411.630005  85.129997  77.309998  15.167  1.475492\n",
       "3  1/7/2008  1416.180054  84.769997  75.500000  15.053  1.468299\n",
       "4  1/8/2008  1390.189941  86.779999  76.059998  15.590  1.557099"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset using Pandas\n",
    "gold_data = pd.read_csv(\"C:\\\\Projects\\\\Gold Price Prediction\\\\gld_price_data.csv\")\n",
    "#Displaying the first 5 rows of dataset\n",
    "gold_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5985fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the number of rows and columns\n",
    "gold_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c743e0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       0\n",
       "SPX        0\n",
       "GLD        0\n",
       "USO        0\n",
       "SLV        0\n",
       "EUR/USD    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for null values\n",
    "gold_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608e530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting features and target from the dataframe\n",
    "features = gold_data[[\"SPX\",\"USO\",\"SLV\",\"EUR/USD\"]]\n",
    "target = gold_data[[\"GLD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bfe3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into test and train sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(features,target,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd39674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaishnavi Sriyaa N\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor training completed\n"
     ]
    }
   ],
   "source": [
    "#Training using RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators=100)\n",
    "regressor.fit(x_train,y_train)\n",
    "print(\"RandomForestRegressor training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71e70964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 95.20999895,  81.04309947, 120.02939949,  91.50539974,\n",
       "        73.65600098, 117.72089893, 119.07139977, 162.39870462,\n",
       "       122.0025995 ,  81.60919969, 124.97930062, 160.51970174,\n",
       "       159.44270273, 140.64669972, 119.1801006 , 167.35479977,\n",
       "       119.00229945, 168.30319713, 108.35499906, 127.62300024,\n",
       "       103.48770054, 160.87959938, 148.25920055, 149.12990301,\n",
       "        90.64770041, 125.79290118,  92.47900061, 112.22120087,\n",
       "       139.33780229, 113.57110056,  86.68829822, 110.23090092,\n",
       "       104.00959969, 101.88309872, 126.88759948,  89.4221998 ,\n",
       "       119.20870119, 168.74209606, 116.59910039,  91.90589939,\n",
       "        85.51049965, 115.1922995 , 151.83129675, 125.36649967,\n",
       "       115.36880004, 105.41120146, 165.53010226,  91.86290102,\n",
       "       145.45010187,  88.65489982, 116.72150029, 166.94100037,\n",
       "       114.17479962,  92.97400026, 116.45030019, 125.19189881,\n",
       "       125.07370003, 119.15309996, 119.28919999, 167.74709598,\n",
       "       122.49269979, 105.0158004 ,  73.00850038,  85.08389835,\n",
       "       128.4829015 , 108.52760009, 101.3738986 , 167.14870119,\n",
       "       117.65430001, 126.21620173, 120.1311012 , 102.62249981,\n",
       "       153.00430023, 112.02970039, 123.95420085, 104.24120097,\n",
       "       120.01299913, 165.63150341,  93.4514992 , 119.3240994 ,\n",
       "       117.12029946, 125.20070047, 127.24070138, 111.94049971,\n",
       "       131.72240221, 125.73789953, 169.38379995, 118.40230047,\n",
       "       129.77590082, 119.82519959, 167.27930169, 116.18259744,\n",
       "       106.82469898, 124.90260029,  98.12730239, 104.02189911,\n",
       "       161.76309864, 120.91130089, 139.50069963, 125.51220122,\n",
       "       116.81049978, 106.90679923, 122.64160058, 117.5152003 ,\n",
       "        91.69130139, 111.12349981, 115.16089949, 122.21380107,\n",
       "        92.06609997, 120.31230178, 139.38109946, 120.95330074,\n",
       "       115.49620047, 101.32009871, 121.38280069, 120.07959963,\n",
       "       120.02279937, 153.50790006, 127.76940218, 115.12870111,\n",
       "       120.25740058, 119.06180172, 126.38109957, 155.67590438,\n",
       "       162.53870119, 159.41660349, 125.5972    , 124.71649985,\n",
       "       130.37780087, 124.50149936, 140.12470109, 133.28320073,\n",
       "       120.11240024, 156.81230066,  89.47729931,  92.98350058,\n",
       "       166.88579954, 129.6576995 , 122.3742996 , 119.91020058,\n",
       "       122.24620024, 124.21559972, 117.56600084, 125.42040287,\n",
       "       113.98920062,  86.31599845, 122.22770059, 122.6819998 ,\n",
       "       148.59490181,  88.6722998 , 107.15040114, 168.28189874,\n",
       "       150.98200225, 121.18410018, 125.72909967,  90.75299986,\n",
       "       125.14580005, 119.3347998 , 135.17729786, 120.36000022,\n",
       "       114.21380022, 151.51849964, 121.59080017, 116.39020007,\n",
       "       125.05610173, 135.92550086,  91.83769996, 102.55829895,\n",
       "       167.08829956, 132.1006991 , 119.94199861, 178.55469933,\n",
       "        87.06459853, 176.03680036,  78.67210043, 132.39440044,\n",
       "       102.61459908, 112.3065998 , 147.63179992, 131.47829903,\n",
       "       151.50240226, 117.94860079, 152.45950074, 122.61040112,\n",
       "        93.55099954, 161.53739837, 115.23710033, 113.17490068,\n",
       "       105.68300049, 120.25149994, 155.78130296, 163.49580031,\n",
       "       119.50910055, 116.63990069, 102.4895006 ,  91.80519924,\n",
       "       111.41980039, 108.48499806, 125.49419817, 133.18530331,\n",
       "       171.89219749, 119.32110034,  88.8471    , 156.53220117,\n",
       "       146.21739909, 120.01090193,  90.76539947, 113.52340135,\n",
       "       160.6841004 , 170.90839717, 169.01910001, 123.68579972,\n",
       "       123.026899  , 162.73220136,  91.42720012, 124.19319994,\n",
       "       127.21409935, 160.31030069,  92.51589952, 122.02020034,\n",
       "       127.89049905, 124.88450118, 121.20659929, 135.34810086,\n",
       "       111.74809953, 127.86570233, 126.83769969, 125.84659922,\n",
       "        92.42389991,  92.61020083, 161.08940233,  79.89490092,\n",
       "       102.0542001 , 170.25890096, 153.10420087, 124.84140013,\n",
       "       174.20210021, 124.99880068, 123.46210033, 112.88479975,\n",
       "       102.55440031, 147.27299977, 127.81450247, 159.10440179,\n",
       "       102.91149897, 118.61860057, 160.62190356, 108.72599901,\n",
       "       113.18169868, 118.94150002, 125.65759849,  72.79390102,\n",
       "       110.84289896, 109.25830013, 118.84870024,  84.76359981,\n",
       "       166.31119912, 117.69199983,  90.92060078, 122.36139852,\n",
       "       124.71433838, 167.43830146, 110.20550024, 127.77589861,\n",
       "       132.32570033, 122.83559993, 127.36620161, 134.80160014,\n",
       "       128.02520253,  94.26630058, 136.69119899, 107.39440092,\n",
       "       136.78399876, 135.57180079, 118.23890033, 139.81779858,\n",
       "       117.857098  , 126.91710022,  90.54639953, 126.00329821,\n",
       "       152.45450396, 114.40129939, 122.87169946, 116.43119846,\n",
       "        91.7075993 , 121.06789981, 126.19000016, 155.79789959,\n",
       "       114.75920017,  85.89820071, 124.0532991 , 125.14129998,\n",
       "       120.58460177, 121.54659957, 121.94109952,  89.33640012,\n",
       "        97.79829713, 115.34839939, 124.89309905, 118.53900018,\n",
       "       128.32979907, 130.56510076, 127.49030002, 155.61160036,\n",
       "        93.97930048, 126.38710004, 121.03720018, 118.01779961,\n",
       "       111.82700045, 143.03560015, 126.12679976,  90.89770183,\n",
       "       133.83729753, 120.24590188, 120.95610034,  92.52439976,\n",
       "        92.71220107,  89.28120078, 101.50809905, 126.3714003 ,\n",
       "       106.602799  ,  92.22419939, 120.98789991, 108.72120045,\n",
       "        72.30620171, 119.59440011, 115.4306008 , 108.96050077,\n",
       "       124.13740032, 172.94069963, 111.81479806, 153.99830163,\n",
       "       116.09690012, 120.4535992 , 117.0558008 , 168.06709758,\n",
       "       167.72279962, 113.48320012, 120.53070038,  87.57430002,\n",
       "       164.84119991, 122.8245002 , 124.08470169, 165.52990008,\n",
       "       168.3981993 , 159.22530132, 155.21860311, 126.32550195,\n",
       "       165.11909908, 120.80340059, 115.7395999 , 111.81729945,\n",
       "       120.31859945,  84.24129912, 117.66820037, 115.06880014,\n",
       "       113.67620183,  91.74579961, 112.2900995 ,  83.86629981,\n",
       "       111.95360117,  84.34859974, 143.66430245, 114.37779992,\n",
       "       125.80370129, 170.4138004 , 117.70070072,  88.09619893,\n",
       "        91.0783006 , 162.63990065, 115.9879011 , 110.9372996 ,\n",
       "       154.39960076, 160.29930224, 137.28950371,  97.31559788,\n",
       "       119.57220113, 151.79050127, 163.44100441,  91.47459925,\n",
       "        73.33120007, 114.59689977,  89.86939868,  91.78650004,\n",
       "       107.82309962, 123.15349993, 112.86909921, 123.9626996 ,\n",
       "       146.12289937, 116.6996008 , 117.83670101, 109.17199893,\n",
       "       102.15980017,  93.96190058, 121.03919988, 134.41200055,\n",
       "       124.28969894, 148.96420086, 118.93070148, 162.25390216,\n",
       "       152.14750013, 122.84569865, 141.48179999, 124.08779905,\n",
       "       120.86429971, 114.10300033, 133.04580033, 156.12350087,\n",
       "       125.79180077, 136.54800117, 127.9572028 , 154.57870008,\n",
       "       123.73569908, 118.79599944, 163.38390203, 122.09019902,\n",
       "       108.53300137,  91.79580002, 117.67339825, 106.90759885,\n",
       "        92.51419956, 111.85510016, 126.24490198, 120.74629871,\n",
       "        85.70980021,  89.23919989, 140.8347005 , 131.06030088,\n",
       "       145.05990104, 126.61149907, 170.39230184, 124.5171007 ,\n",
       "       120.92850041, 113.82789982,  87.79180082, 112.59469967,\n",
       "       119.80920056, 153.27560066, 154.50750136, 117.92960069,\n",
       "       136.16310067, 114.56329819, 131.42250053, 112.8067012 ,\n",
       "       122.46429851, 120.95149865,  87.53419962, 102.39479897,\n",
       "       141.62100112, 115.45820032, 160.45960412, 121.66030102,\n",
       "        86.17819879,  73.8737004 , 140.76059892, 133.17210403,\n",
       "       128.89710176, 135.35980097])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting using RandomForestRegressor\n",
    "regressor_predictions = regressor.predict(x_test)\n",
    "regressor_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a72887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 Score:  0.9895717082722558\n"
     ]
    }
   ],
   "source": [
    "#Finding the r2 score to check error\n",
    "error = metrics.r2_score(y_test,regressor_predictions)\n",
    "print(\"The R2 Score: \",error)\n",
    "#Please note that my r2_score has been noted after several iterations of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a9761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Compilation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaishnavi Sriyaa N\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Training Gold Data using Neural Network\n",
    "model = Sequential([\n",
    "    Dense(units=10,activation='relu',input_dim=4),\n",
    "    Dense(units=10,activation='relu'),\n",
    "    Dense(units=1,activation='linear')\n",
    "])\n",
    "#Compiling the neural network with mean_squared_error loss and adam optimizer\n",
    "model.compile(loss='mean_squared_error',optimizer='Adam')\n",
    "print(\"Neural Network Compilation Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1fda90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2889.2793\n",
      "Epoch 2/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2466.5635\n",
      "Epoch 3/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2294.8701\n",
      "Epoch 4/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2088.5608\n",
      "Epoch 5/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2008.1952\n",
      "Epoch 6/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1995.3271\n",
      "Epoch 7/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1898.1659\n",
      "Epoch 8/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1829.1133\n",
      "Epoch 9/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1748.3337\n",
      "Epoch 10/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1705.3928\n",
      "Epoch 11/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1748.9100\n",
      "Epoch 12/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1618.4982\n",
      "Epoch 13/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1498.0736\n",
      "Epoch 14/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1517.3191\n",
      "Epoch 15/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1328.5575\n",
      "Epoch 16/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1312.6089\n",
      "Epoch 17/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1193.1426\n",
      "Epoch 18/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1111.2318\n",
      "Epoch 19/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 996.3184\n",
      "Epoch 20/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 935.9131\n",
      "Epoch 21/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 809.4993\n",
      "Epoch 22/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 705.7778\n",
      "Epoch 23/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 694.9053\n",
      "Epoch 24/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 624.7675\n",
      "Epoch 25/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 580.8856\n",
      "Epoch 26/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 503.4653\n",
      "Epoch 27/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.7446\n",
      "Epoch 28/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.1443\n",
      "Epoch 29/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.6077\n",
      "Epoch 30/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.8230\n",
      "Epoch 31/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329.0801\n",
      "Epoch 32/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320.1557\n",
      "Epoch 33/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.1546\n",
      "Epoch 34/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.1582\n",
      "Epoch 35/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281.4042\n",
      "Epoch 36/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.8440\n",
      "Epoch 37/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.9727\n",
      "Epoch 38/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.8428\n",
      "Epoch 39/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.1407\n",
      "Epoch 40/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177.5000\n",
      "Epoch 41/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.4794\n",
      "Epoch 42/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155.7640\n",
      "Epoch 43/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.8349\n",
      "Epoch 44/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.1999\n",
      "Epoch 45/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137.1655\n",
      "Epoch 46/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.0017\n",
      "Epoch 47/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.7786\n",
      "Epoch 48/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.1925\n",
      "Epoch 49/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.1668\n",
      "Epoch 50/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.8414\n",
      "Epoch 51/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.9716\n",
      "Epoch 52/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127.3405\n",
      "Epoch 53/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.5998\n",
      "Epoch 54/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.7989\n",
      "Epoch 55/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.2535\n",
      "Epoch 56/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.7290\n",
      "Epoch 57/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.6408\n",
      "Epoch 58/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.5567\n",
      "Epoch 59/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.3733\n",
      "Epoch 60/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134.1840\n",
      "Epoch 61/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.9933\n",
      "Epoch 62/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.3979\n",
      "Epoch 63/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.4394\n",
      "Epoch 64/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.8621\n",
      "Epoch 65/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.7211\n",
      "Epoch 66/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.3107\n",
      "Epoch 67/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.3796\n",
      "Epoch 68/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.5395\n",
      "Epoch 69/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.5601\n",
      "Epoch 70/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.6140\n",
      "Epoch 71/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.9863\n",
      "Epoch 72/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124.2410\n",
      "Epoch 73/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.0833\n",
      "Epoch 74/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130.9162\n",
      "Epoch 75/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.3807\n",
      "Epoch 76/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.7745\n",
      "Epoch 77/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.9699\n",
      "Epoch 78/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.6079\n",
      "Epoch 79/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.8527 \n",
      "Epoch 80/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.6249\n",
      "Epoch 81/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.5523\n",
      "Epoch 82/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.0762\n",
      "Epoch 83/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.3720\n",
      "Epoch 84/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.6220\n",
      "Epoch 85/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.3904\n",
      "Epoch 86/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124.2413\n",
      "Epoch 87/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 107.8170\n",
      "Epoch 88/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.3302\n",
      "Epoch 89/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.0660\n",
      "Epoch 90/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.5654\n",
      "Epoch 91/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.8993\n",
      "Epoch 92/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.9575\n",
      "Epoch 93/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.9390\n",
      "Epoch 94/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.5133 \n",
      "Epoch 95/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.2161\n",
      "Epoch 96/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.9787\n",
      "Epoch 97/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.6603\n",
      "Epoch 98/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.5023\n",
      "Epoch 99/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.8147\n",
      "Epoch 100/100\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.7974\n",
      "Neural Network Training Completed\n"
     ]
    }
   ],
   "source": [
    "#Training neural network [multiple iterations]\n",
    "model.fit(x_train,y_train,epochs=100)\n",
    "print(\"Neural Network Training Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96ae61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 81.5599  ],\n",
       "       [ 78.62    ],\n",
       "       [120.083496],\n",
       "       [ 81.6982  ],\n",
       "       [ 67.66683 ],\n",
       "       [112.46809 ],\n",
       "       [119.05104 ],\n",
       "       [152.47942 ],\n",
       "       [121.9492  ],\n",
       "       [ 69.31842 ],\n",
       "       [122.14892 ],\n",
       "       [150.63025 ],\n",
       "       [147.50592 ],\n",
       "       [130.92822 ],\n",
       "       [122.03319 ],\n",
       "       [157.64348 ],\n",
       "       [119.49143 ],\n",
       "       [159.38234 ],\n",
       "       [ 97.30251 ],\n",
       "       [126.06678 ],\n",
       "       [ 99.72129 ],\n",
       "       [148.12534 ],\n",
       "       [200.27081 ],\n",
       "       [163.38365 ],\n",
       "       [ 82.588196],\n",
       "       [123.115746],\n",
       "       [ 82.69451 ],\n",
       "       [109.988686],\n",
       "       [171.14772 ],\n",
       "       [111.06604 ],\n",
       "       [ 74.55783 ],\n",
       "       [107.45932 ],\n",
       "       [105.19743 ],\n",
       "       [ 93.02438 ],\n",
       "       [125.280846],\n",
       "       [ 75.101974],\n",
       "       [107.58846 ],\n",
       "       [161.22293 ],\n",
       "       [117.64795 ],\n",
       "       [ 99.98625 ],\n",
       "       [ 73.545204],\n",
       "       [111.76139 ],\n",
       "       [140.36948 ],\n",
       "       [121.55267 ],\n",
       "       [112.33883 ],\n",
       "       [ 97.68522 ],\n",
       "       [158.1018  ],\n",
       "       [ 81.96654 ],\n",
       "       [144.99693 ],\n",
       "       [ 76.63723 ],\n",
       "       [118.04657 ],\n",
       "       [186.51953 ],\n",
       "       [118.91872 ],\n",
       "       [ 86.31834 ],\n",
       "       [115.331894],\n",
       "       [124.25116 ],\n",
       "       [121.05521 ],\n",
       "       [121.262794],\n",
       "       [119.605446],\n",
       "       [158.9718  ],\n",
       "       [116.07263 ],\n",
       "       [100.46336 ],\n",
       "       [ 64.43706 ],\n",
       "       [ 95.31317 ],\n",
       "       [126.520325],\n",
       "       [ 98.133125],\n",
       "       [101.86344 ],\n",
       "       [155.12878 ],\n",
       "       [105.597435],\n",
       "       [112.15637 ],\n",
       "       [123.37222 ],\n",
       "       [104.38593 ],\n",
       "       [137.58511 ],\n",
       "       [108.52766 ],\n",
       "       [115.014946],\n",
       "       [ 98.02807 ],\n",
       "       [119.58607 ],\n",
       "       [152.37915 ],\n",
       "       [101.15194 ],\n",
       "       [116.42703 ],\n",
       "       [120.73599 ],\n",
       "       [116.27459 ],\n",
       "       [125.75698 ],\n",
       "       [103.62407 ],\n",
       "       [122.42602 ],\n",
       "       [116.4812  ],\n",
       "       [161.41284 ],\n",
       "       [119.03715 ],\n",
       "       [124.67168 ],\n",
       "       [115.05809 ],\n",
       "       [158.63817 ],\n",
       "       [119.669334],\n",
       "       [ 93.91177 ],\n",
       "       [125.23227 ],\n",
       "       [ 93.83707 ],\n",
       "       [ 98.63365 ],\n",
       "       [153.37991 ],\n",
       "       [123.32715 ],\n",
       "       [166.5839  ],\n",
       "       [124.24243 ],\n",
       "       [105.661514],\n",
       "       [ 99.2249  ],\n",
       "       [124.28202 ],\n",
       "       [121.60335 ],\n",
       "       [ 79.04392 ],\n",
       "       [101.78371 ],\n",
       "       [ 99.077385],\n",
       "       [115.11667 ],\n",
       "       [ 81.528435],\n",
       "       [119.56197 ],\n",
       "       [164.15599 ],\n",
       "       [123.46106 ],\n",
       "       [113.24037 ],\n",
       "       [ 96.74845 ],\n",
       "       [123.48647 ],\n",
       "       [116.78723 ],\n",
       "       [117.20029 ],\n",
       "       [175.86736 ],\n",
       "       [129.3699  ],\n",
       "       [111.95006 ],\n",
       "       [101.638824],\n",
       "       [107.26716 ],\n",
       "       [123.53235 ],\n",
       "       [139.20506 ],\n",
       "       [155.83502 ],\n",
       "       [150.5505  ],\n",
       "       [120.34439 ],\n",
       "       [120.71381 ],\n",
       "       [134.953   ],\n",
       "       [119.213806],\n",
       "       [148.68687 ],\n",
       "       [127.36503 ],\n",
       "       [122.69901 ],\n",
       "       [165.90253 ],\n",
       "       [ 99.828575],\n",
       "       [ 79.1676  ],\n",
       "       [157.94926 ],\n",
       "       [128.17195 ],\n",
       "       [115.240654],\n",
       "       [123.43221 ],\n",
       "       [121.61384 ],\n",
       "       [118.5944  ],\n",
       "       [122.04464 ],\n",
       "       [123.66188 ],\n",
       "       [109.37402 ],\n",
       "       [ 73.38537 ],\n",
       "       [115.10637 ],\n",
       "       [116.882996],\n",
       "       [145.36511 ],\n",
       "       [ 99.18469 ],\n",
       "       [107.87772 ],\n",
       "       [165.2793  ],\n",
       "       [153.22546 ],\n",
       "       [102.60544 ],\n",
       "       [124.66964 ],\n",
       "       [ 97.87026 ],\n",
       "       [119.3899  ],\n",
       "       [118.890305],\n",
       "       [140.05447 ],\n",
       "       [117.85897 ],\n",
       "       [117.15455 ],\n",
       "       [135.72977 ],\n",
       "       [118.46412 ],\n",
       "       [104.34352 ],\n",
       "       [122.5614  ],\n",
       "       [126.62927 ],\n",
       "       [ 82.162155],\n",
       "       [104.16936 ],\n",
       "       [156.853   ],\n",
       "       [118.51128 ],\n",
       "       [120.496185],\n",
       "       [186.50644 ],\n",
       "       [ 97.92097 ],\n",
       "       [185.16663 ],\n",
       "       [ 69.26243 ],\n",
       "       [127.03682 ],\n",
       "       [102.53687 ],\n",
       "       [111.018196],\n",
       "       [141.46445 ],\n",
       "       [128.83104 ],\n",
       "       [163.73709 ],\n",
       "       [105.57437 ],\n",
       "       [134.95566 ],\n",
       "       [124.03367 ],\n",
       "       [101.6091  ],\n",
       "       [150.77066 ],\n",
       "       [112.15162 ],\n",
       "       [109.18207 ],\n",
       "       [103.80507 ],\n",
       "       [116.068695],\n",
       "       [139.97403 ],\n",
       "       [157.38153 ],\n",
       "       [109.852776],\n",
       "       [111.46702 ],\n",
       "       [ 95.12031 ],\n",
       "       [ 99.098236],\n",
       "       [109.2656  ],\n",
       "       [ 93.52115 ],\n",
       "       [124.82855 ],\n",
       "       [147.38644 ],\n",
       "       [163.9857  ],\n",
       "       [118.8583  ],\n",
       "       [ 99.78418 ],\n",
       "       [183.22221 ],\n",
       "       [164.54765 ],\n",
       "       [117.25846 ],\n",
       "       [ 97.89046 ],\n",
       "       [102.78343 ],\n",
       "       [148.89093 ],\n",
       "       [164.2329  ],\n",
       "       [161.60278 ],\n",
       "       [114.792274],\n",
       "       [116.59787 ],\n",
       "       [154.7633  ],\n",
       "       [ 78.539955],\n",
       "       [119.880646],\n",
       "       [123.5425  ],\n",
       "       [154.15952 ],\n",
       "       [102.697   ],\n",
       "       [121.089035],\n",
       "       [126.2301  ],\n",
       "       [123.240524],\n",
       "       [123.14084 ],\n",
       "       [129.5192  ],\n",
       "       [108.262344],\n",
       "       [130.38261 ],\n",
       "       [124.83515 ],\n",
       "       [125.877625],\n",
       "       [ 82.59287 ],\n",
       "       [ 82.65471 ],\n",
       "       [150.88306 ],\n",
       "       [ 68.64755 ],\n",
       "       [103.80037 ],\n",
       "       [162.40337 ],\n",
       "       [136.18748 ],\n",
       "       [121.091675],\n",
       "       [181.0206  ],\n",
       "       [126.57017 ],\n",
       "       [120.19364 ],\n",
       "       [102.90158 ],\n",
       "       [104.47147 ],\n",
       "       [165.59242 ],\n",
       "       [127.5761  ],\n",
       "       [151.97449 ],\n",
       "       [104.72296 ],\n",
       "       [113.1303  ],\n",
       "       [152.702   ],\n",
       "       [114.04374 ],\n",
       "       [110.463585],\n",
       "       [100.3231  ],\n",
       "       [124.70263 ],\n",
       "       [ 65.09454 ],\n",
       "       [108.78373 ],\n",
       "       [ 97.4366  ],\n",
       "       [117.55055 ],\n",
       "       [ 77.769104],\n",
       "       [169.89127 ],\n",
       "       [113.2805  ],\n",
       "       [ 80.34746 ],\n",
       "       [120.63068 ],\n",
       "       [122.41325 ],\n",
       "       [159.817   ],\n",
       "       [101.261826],\n",
       "       [121.98692 ],\n",
       "       [127.28281 ],\n",
       "       [120.742424],\n",
       "       [125.804504],\n",
       "       [127.53258 ],\n",
       "       [127.61465 ],\n",
       "       [ 88.27504 ],\n",
       "       [141.87747 ],\n",
       "       [101.77075 ],\n",
       "       [143.08139 ],\n",
       "       [125.271164],\n",
       "       [118.04781 ],\n",
       "       [129.05464 ],\n",
       "       [112.23157 ],\n",
       "       [124.54527 ],\n",
       "       [100.17957 ],\n",
       "       [121.429016],\n",
       "       [146.47345 ],\n",
       "       [111.906685],\n",
       "       [124.32391 ],\n",
       "       [119.52183 ],\n",
       "       [ 83.445755],\n",
       "       [101.93254 ],\n",
       "       [124.67139 ],\n",
       "       [141.25429 ],\n",
       "       [116.14692 ],\n",
       "       [ 95.32236 ],\n",
       "       [119.52273 ],\n",
       "       [121.7958  ],\n",
       "       [114.269   ],\n",
       "       [113.76499 ],\n",
       "       [122.07566 ],\n",
       "       [ 78.91513 ],\n",
       "       [111.066414],\n",
       "       [115.00404 ],\n",
       "       [120.10185 ],\n",
       "       [116.68739 ],\n",
       "       [124.88428 ],\n",
       "       [125.328766],\n",
       "       [124.22731 ],\n",
       "       [145.97047 ],\n",
       "       [ 85.51371 ],\n",
       "       [125.54658 ],\n",
       "       [124.60865 ],\n",
       "       [115.44372 ],\n",
       "       [103.3241  ],\n",
       "       [183.52896 ],\n",
       "       [123.03539 ],\n",
       "       [ 76.28551 ],\n",
       "       [132.51619 ],\n",
       "       [119.306915],\n",
       "       [123.92077 ],\n",
       "       [ 84.21565 ],\n",
       "       [ 82.28222 ],\n",
       "       [ 99.49312 ],\n",
       "       [102.10383 ],\n",
       "       [125.371216],\n",
       "       [ 97.23277 ],\n",
       "       [ 76.23314 ],\n",
       "       [100.58729 ],\n",
       "       [103.0988  ],\n",
       "       [ 63.72421 ],\n",
       "       [114.72708 ],\n",
       "       [112.628426],\n",
       "       [109.28925 ],\n",
       "       [120.34198 ],\n",
       "       [178.9646  ],\n",
       "       [113.85693 ],\n",
       "       [145.61649 ],\n",
       "       [110.21484 ],\n",
       "       [101.49797 ],\n",
       "       [118.39918 ],\n",
       "       [158.84903 ],\n",
       "       [158.31697 ],\n",
       "       [110.8893  ],\n",
       "       [121.56835 ],\n",
       "       [ 77.63234 ],\n",
       "       [156.40683 ],\n",
       "       [119.91296 ],\n",
       "       [122.29744 ],\n",
       "       [156.29434 ],\n",
       "       [159.32553 ],\n",
       "       [149.37871 ],\n",
       "       [146.69203 ],\n",
       "       [123.12445 ],\n",
       "       [153.40103 ],\n",
       "       [121.6948  ],\n",
       "       [104.05257 ],\n",
       "       [103.45181 ],\n",
       "       [116.547806],\n",
       "       [ 83.40365 ],\n",
       "       [113.476494],\n",
       "       [105.40563 ],\n",
       "       [109.885414],\n",
       "       [ 83.035995],\n",
       "       [111.01385 ],\n",
       "       [ 72.80911 ],\n",
       "       [116.89333 ],\n",
       "       [ 71.624214],\n",
       "       [147.78204 ],\n",
       "       [118.120605],\n",
       "       [122.87082 ],\n",
       "       [161.50519 ],\n",
       "       [105.02113 ],\n",
       "       [ 98.13008 ],\n",
       "       [ 75.440926],\n",
       "       [155.20282 ],\n",
       "       [113.276825],\n",
       "       [101.88677 ],\n",
       "       [146.45181 ],\n",
       "       [148.76236 ],\n",
       "       [142.42355 ],\n",
       "       [112.73096 ],\n",
       "       [123.293015],\n",
       "       [143.46335 ],\n",
       "       [149.78856 ],\n",
       "       [ 82.247086],\n",
       "       [ 66.65683 ],\n",
       "       [113.14162 ],\n",
       "       [101.3603  ],\n",
       "       [102.994446],\n",
       "       [ 97.48545 ],\n",
       "       [117.90573 ],\n",
       "       [109.064804],\n",
       "       [118.801994],\n",
       "       [161.75139 ],\n",
       "       [107.6773  ],\n",
       "       [110.63255 ],\n",
       "       [102.44672 ],\n",
       "       [104.27518 ],\n",
       "       [ 87.098755],\n",
       "       [116.83084 ],\n",
       "       [131.56221 ],\n",
       "       [118.89293 ],\n",
       "       [143.05624 ],\n",
       "       [107.41159 ],\n",
       "       [152.34253 ],\n",
       "       [142.12903 ],\n",
       "       [121.475716],\n",
       "       [127.60312 ],\n",
       "       [122.98451 ],\n",
       "       [117.876595],\n",
       "       [114.44985 ],\n",
       "       [126.284424],\n",
       "       [140.07645 ],\n",
       "       [124.773766],\n",
       "       [142.18309 ],\n",
       "       [127.49516 ],\n",
       "       [140.91656 ],\n",
       "       [119.913246],\n",
       "       [114.55163 ],\n",
       "       [153.70709 ],\n",
       "       [123.78017 ],\n",
       "       [105.384125],\n",
       "       [101.846214],\n",
       "       [111.72386 ],\n",
       "       [ 95.93336 ],\n",
       "       [ 84.51706 ],\n",
       "       [109.13263 ],\n",
       "       [122.72673 ],\n",
       "       [121.98302 ],\n",
       "       [ 97.57864 ],\n",
       "       [ 99.56639 ],\n",
       "       [144.1186  ],\n",
       "       [122.47064 ],\n",
       "       [144.4368  ],\n",
       "       [129.36957 ],\n",
       "       [161.55817 ],\n",
       "       [121.533005],\n",
       "       [123.74233 ],\n",
       "       [117.40819 ],\n",
       "       [ 77.5231  ],\n",
       "       [108.68244 ],\n",
       "       [119.70628 ],\n",
       "       [158.26611 ],\n",
       "       [139.48016 ],\n",
       "       [122.311554],\n",
       "       [147.50491 ],\n",
       "       [100.79281 ],\n",
       "       [124.53812 ],\n",
       "       [116.68693 ],\n",
       "       [120.914696],\n",
       "       [102.40468 ],\n",
       "       [ 76.676926],\n",
       "       [104.38263 ],\n",
       "       [130.78584 ],\n",
       "       [113.38749 ],\n",
       "       [152.20967 ],\n",
       "       [123.45278 ],\n",
       "       [ 82.51217 ],\n",
       "       [ 66.94419 ],\n",
       "       [129.9153  ],\n",
       "       [124.651535],\n",
       "       [127.33113 ],\n",
       "       [141.5959  ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the values\n",
    "nn_predictions = model.predict(x_test)\n",
    "nn_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d8f039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8377405724226589"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating r2_score\n",
    "error_nn = metrics.r2_score(y_test,nn_predictions)\n",
    "error_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d8858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence After performing several iterations I conclude that ANN (with 0.83774 r2_score) is more efficient than RandomForestRegressor (with 0.989 r2_score)\n",
    "#for the given problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
